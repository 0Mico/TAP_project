input {
  http {
    port => 5000
    codec => json
  }
}

filter {
  mutate {   
    # Remove fields added by the http plugin (ECS)
    remove_field => ["http", "url", "user_agent", "@version", "host", "event"]
  }
  
  if ![Description] or [Description] == "" {
    drop {}
  }

  # Check if the document already exists in Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "deduped_posts"
    query => "Job_ID:%{Job_ID}"  # Query using the Job_ID
    fields => { "Description" => "old_description" }
  }

  # Save the document only if it is new or contains more informations than its old copy
  if [old_description] {         # Document with the same Job_ID exists
    if [old_description] != "" { # Old copy already contains the description
      drop {}
    }
  }
}

output {
  elasticsearch {   # Indexes events which wasn't dropped. Will overwrite if duplicate
    hosts => ["http://elasticsearch:9200"]
    index => "deduped_posts"
    document_id => "%{Job_ID}"
    codec => json
  }
  kafka {  # ...and write the event in kafka topic: the job certainly contains a Description
    bootstrap_servers => "kafka:9092"
    topic_id => "deduped_job_posts"
    codec => json
  }
} 